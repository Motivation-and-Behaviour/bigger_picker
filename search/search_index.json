{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Bigger Picture Screening and Extraction Documentation","text":"<p>These docs are the internal documentation for the Bigger Picture team. They cover:</p> <ul> <li>Screening articles to identify relevant datasets in Rayyan.</li> <li>Extracting data about those datasets (both manually, and using the Bigger Picker tool).</li> <li>Dataset management in Airtable and Asana.</li> <li>Contacting authors.</li> </ul>"},{"location":"cli/","title":"CLI Reference","text":"<p>The Bigger Picker tool is a command-line interface (CLI) for syncing the various applications used by the Bigger Picture team. It orchestrates the automated data extraction process for articles identified in Rayyan, and maintains a sync between Rayyan, Airtable, and Asana.</p> <p>These docs are a very brief reference for how to use the CLI tool.</p>"},{"location":"cli/#installation","title":"Installation","text":"<ol> <li> <p>Clone the repository:</p> <pre><code>git clone &lt;https://github.com/Motivation-and-Behaviour/bigger_picker.git&gt;\ncd bigger_picker\n</code></pre> </li> <li> <p>Install dependencies:</p> <pre><code>pip install -e .\n</code></pre> <p>You can also optionally install the development dependencies:</p> <pre><code>pip install -e .[dev]\n</code></pre> </li> <li> <p>Set up your <code>.env</code> file with the required API keys and configuration values.    The provided <code>.env.example</code> can be used as a template.</p> </li> </ol>"},{"location":"cli/#configuration","title":"Configuration","text":"<p>Most settings for the project are set in the bigger_picker/config.py file. If you are using this package for a project other than the Bigger Picture, you will need to adjust the settings there. Some other components are also hardcoded.</p> <p>You will need API keys for Airtable, Asana, and OpenAI. You will also need a <code>rayyan_tokens.json</code> file for Rayyan API authentication.</p>"},{"location":"cli/#usage","title":"Usage","text":"<p>Once installed, you can use the command-line interface (CLI) to interact with the Bigger Picker tools.</p> <p>The methods for interacting with the CLI are outlined below.</p>"},{"location":"cli/#bigger-picker","title":"bigger-picker","text":"<p>Usage:</p> <pre><code>bigger-picker [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> <pre><code>  --install-completion  Install completion for the current shell.\n  --show-completion     Show completion for the current shell, to copy it or\n                        customize the installation.\n  --help                Show this message and exit.\n</code></pre>"},{"location":"cli/#bigger-picker-process","title":"bigger-picker process","text":"<p>Usage:</p> <pre><code>bigger-picker process [OPTIONS]\n</code></pre> <p>Options:</p> <pre><code>  --dotenv-path TEXT        Path to .env file with credentials\n  --airtable-api-key TEXT   Airtable API key\n  --asana-token TEXT        Asana API token\n  --openai-api-key TEXT     OpenAI API key\n  --openai-model TEXT       OpenAI model to use  \\[default: gpt-4.1]\n  --rayyan-creds-path TEXT  Path to Rayyan credentials JSON file\n  --debug                   Enable debug logging to console\n  --help                    Show this message and exit.\n</code></pre>"},{"location":"cli/#bigger-picker-sync","title":"bigger-picker sync","text":"<p>Usage:</p> <pre><code>bigger-picker sync [OPTIONS]\n</code></pre> <p>Options:</p> <pre><code>  --dotenv-path TEXT        Path to .env file with credentials\n  --airtable-api-key TEXT   Airtable API key\n  --asana-token TEXT        Asana API token\n  --openai-api-key TEXT     OpenAI API key\n  --openai-model TEXT       OpenAI model to use  \\[default: gpt-4.1]\n  --rayyan-creds-path TEXT  Path to Rayyan credentials JSON file\n  --debug                   Enable debug logging to console\n  --help                    Show this message and exit.\n</code></pre>"},{"location":"manual/","title":"Overview","text":""},{"location":"manual/#project-overview","title":"Project Overview","text":"<p>We are conducting a individual participant data (IPD) meta-analysis to better understand the impact of screen time on children's learning, cognitive abilities, mental health, wellbeing, and behaviour. This is part of the Bigger Picture project.</p> <p>To conduct an IPD meta-analysis, we need to identify datasets which contain relevant data, determine which of those datasets we will try to access, and then work with the people who manage those datasets (data custodians) to access the data.</p>"},{"location":"manual/#identifying-datasets","title":"Identifying Datasets","text":"<p>We have used two methods to identify datasets:</p> <ol> <li>Our 2023 Umbrella Review, which identified 102 meta-analyses on screen time.    We extracted the cited studies from these meta-analyses.</li> <li>A systematic search of the literature using Scopus.    We extracted the search terms from the above meta-analyses, and the search strategy from the umbrella review, and created a single search strategy.</li> </ol>"},{"location":"manual/#screening-articles","title":"Screening Articles","text":"<p>We need to screen the articles we have identified to determine which ones contain datasets that we want to access. We do this using Rayyan, a web-based tool for screening articles. Full details of the screening process are in the Screening section of the documentation.</p>"},{"location":"manual/#extracting-data","title":"Extracting Data","text":"<p>In order to evaluate which datasets to access, we need to extract data from the articles we have screened. We use two tools for this: Airtable for storing the data, and Asana for tracking the datasets. We use a combination of automated extraction using the Bigger Picker tool and manual checking to confirm the data. Full details of the extraction process are in the Extraction section of the documentation.</p>"},{"location":"manual/#dataset-management","title":"Dataset Management","text":"<p>Once we have decided which datasets to access, we need to work with the data custodians to access the data. It's really important that we are systematic and organised in our approach to this, as we want to avoid duplication of effort and ensure that we are respectful of the data custodians' time. We use Asana to manage our interactions with the data custodians, and to track the progress of our requests. Full details of the dataset management process are in the Data Management section</p>"},{"location":"manual/extraction_addremove/","title":"Adding or Removing Populations, Screen Time Measures, and Outcomes","text":""},{"location":"manual/extraction_addremove/#adding-an-additional-populationscreen-time-measureoutcome","title":"Adding an Additional Population/Screen Time Measure/Outcome","text":"<p>If you find that the AI extraction has missed a population, screen time measure, or outcome, you can add it manually. It is easiest to do this from the form view.</p>"},{"location":"manual/extraction_addremove/#1-click-on-add-record","title":"1. Click on Add record","text":""},{"location":"manual/extraction_addremove/#2-click-on-create-a-new-record","title":"2. Click on Create a new record","text":""},{"location":"manual/extraction_addremove/#3-complete-the-form","title":"3. Complete the form","text":"<p>Enter the details of the population, screen time measure, or outcome in the form. Close the form when you are done to save the record.</p>"},{"location":"manual/extraction_addremove/#removing-incorrect-populationsscreen-time-measuresoutcomes","title":"Removing Incorrect Populations/Screen Time Measures/Outcomes","text":"<p>If you find that the AI has added an incorrect population, screen time measure, or outcome, you can remove it. This is especially common for outcomes, where the AI may mistake a covariate for an outcome.</p>"},{"location":"manual/extraction_addremove/#from-the-form-view","title":"From the Form View","text":""},{"location":"manual/extraction_addremove/#1-click-on-more-options","title":"1. Click on More options","text":"<p>If you click into the unneeded record, you will see a \"More options\" button in the top right corner of the record.</p> <p></p>"},{"location":"manual/extraction_addremove/#2-click-on-delete-record","title":"2. Click on Delete record","text":""},{"location":"manual/extraction_addremove/#from-the-list-view","title":"From the List View","text":"<p>Alternatively, you can right-click on the record in the list view and select \"Delete record\" from the context menu. Be careful to select the correct record, as this will delete it permanently.</p>"},{"location":"manual/extraction_addremove/#1-open-the-list-view-of-the-domain","title":"1. Open the list view of the domain","text":"<p>Open the list view of the domain in which you want to remove the record.</p>"},{"location":"manual/extraction_addremove/#2-right-click-on-the-record","title":"2. Right-click on the record","text":"<p>Then click on Delete record</p> <p></p>"},{"location":"manual/extraction_addvalidated/","title":"Adding New Validated Outcomes","text":""},{"location":"manual/extraction_addvalidated/#rationale","title":"Rationale","text":"<p>When adding validated outcomes, you will often need to create a new option in the \"Validated Outcome\" field. The more data that is validated, the less we should need to do this.</p> <p>It's important to check the existing validated outcomes before creating a new one. We want to avoid creating duplicates, and it might be that it is better to tweak an existing validated outcome than to create a new one. At the same time, we can always fix these later, so don't worry too much about getting it perfect.</p> <p>The process for adding a new validated outcome starts while you are checking the outcomes.</p>"},{"location":"manual/extraction_addvalidated/#adding-a-new-validated-outcome","title":"Adding a New Validated Outcome","text":""},{"location":"manual/extraction_addvalidated/#1-click-on-add-option","title":"1. Click on Add option","text":""},{"location":"manual/extraction_addvalidated/#2-search-for-an-existing-validated-outcome","title":"2. Search for an existing validated outcome","text":"<p>In the search box you can search for existing validated outcomes. If you find one that matches, you can select it and there is no need to complete the next steps.</p>"},{"location":"manual/extraction_addvalidated/#3-click-on-create-a-new-option","title":"3. Click on Create a new option","text":""},{"location":"manual/extraction_addvalidated/#4-type-the-name-of-the-validated-outcome","title":"4. Type the name of the validated outcome","text":""},{"location":"manual/extraction_addvalidated/#5-add-the-outcome-group","title":"5. Add the outcome group","text":""},{"location":"manual/extraction_addvalidated/#6-click-on-close-button","title":"6. Click on Close button","text":""},{"location":"manual/extraction_dedupe/","title":"Deduplicating Datasets","text":""},{"location":"manual/extraction_dedupe/#rationale","title":"Rationale","text":"<p>Since our primary method of finding datasets is via published articles, it is inevitable that we will end up with some articles that use the same dataset. This is not a problem, but we want to merge these so that each dataset we are tracking is unique.</p>"},{"location":"manual/extraction_dedupe/#identifying-duplicate-datasets","title":"Identifying Duplicate Datasets","text":"<p>We mark potential duplicate datasets in the 'Possible Duplicates' field in Airtable. These are links to other datasets that match on one or many fields, such as the dataset name or the dataset contact. These are only an indication though, and it is worth checking if there are other potential duplicates that need to be merged.</p> <p>Some other methods to identify duplicates include:</p> <ul> <li>Sorting the datasets table by the Dataset Contact Name, or the the Dataset Name.</li> <li>Searching using either the filter or the 'Find in View' feature.   This is useful for checking names, as sometimes the title of the contact is included (e.g., \"Dr. John Smith\"), which means that sorting by the contact name will not work.</li> </ul> Tip <p>One other common way to have a duplicate is in the case of longitudinal study designs. It is common for longitudinal studies to report on baseline results, and separately on longitudinal results. In general, the longitudinal dataset is the one we want to keep, as it includes the baseline data.</p>"},{"location":"manual/extraction_dedupe/#overview-of-steps","title":"Overview of Steps","text":"<p>Once you have identified that a dataset is a duplicate, you will need to go through the steps of deduplicating it. The full process is below, but the general steps are:</p> <ol> <li>Validate the articles on both datasets (and the outcomes, etc)</li> <li>Pick one dataset to be the \"main\" dataset.    We will call the other dataset the \"duplicate\" dataset.</li> <li>On the \"main\" dataset, add the article referenced in the \"duplicate\" dataset using the article ID.    This will automatically add the populations, screen time measures, and outcomes from the \"duplicate\" dataset.</li> <li>Check the fields on the \"main\" dataset to see if they need to be updated.    For example, the contact person may need to be updated, or the total sample size may be changed.</li> <li>In Airtable, delete the \"duplicate\" dataset.</li> <li>In Asana, delete the \"duplicate\" dataset task.</li> </ol>"},{"location":"manual/extraction_dedupe/#deduplicating-a-dataset","title":"Deduplicating a Dataset","text":"<p>For the below example, I'll be deduplicating these two datasets. Throughout the process, I will refer to the dataset with the ID <code>BPIPD-92</code> as the main dataset, and the dataset with the ID <code>BPIPD-39</code> as the duplicate dataset.</p> <p></p>"},{"location":"manual/extraction_dedupe/#airtable-steps","title":"Airtable Steps","text":""},{"location":"manual/extraction_dedupe/#get-the-article-id-of-the-duplicate-dataset","title":"Get the Article ID of the duplicate dataset","text":""},{"location":"manual/extraction_dedupe/#1-click-on-the-article-id-of-the-duplicate-dataset","title":"1. Click on the Article ID of the duplicate dataset","text":""},{"location":"manual/extraction_dedupe/#2-copy-the-article-id","title":"2. Copy the Article ID","text":""},{"location":"manual/extraction_dedupe/#3-then-close-the-form","title":"3. Then close the form","text":""},{"location":"manual/extraction_dedupe/#add-the-article-id-to-the-main-dataset","title":"Add the Article ID to the main dataset","text":""},{"location":"manual/extraction_dedupe/#1-open-the-form-for-the-main-dataset","title":"1. Open the form for the main dataset","text":""},{"location":"manual/extraction_dedupe/#2-click-the-add-article-button","title":"2. Click the \"Add Article\" button","text":""},{"location":"manual/extraction_dedupe/#3-paste-the-article-id-into-the-search","title":"3. Paste the Article ID into the search","text":""},{"location":"manual/extraction_dedupe/#4-select-the-article-to-add-it-to-the-main-dataset","title":"4. Select the article to add it to the main dataset","text":""},{"location":"manual/extraction_dedupe/#5-then-close-the-form","title":"5. Then close the form","text":""},{"location":"manual/extraction_dedupe/#delete-the-duplicate-dataset","title":"Delete the duplicate dataset","text":""},{"location":"manual/extraction_dedupe/#1-right-click-on-the-duplicate-dataset","title":"1. Right click on the duplicate dataset","text":""},{"location":"manual/extraction_dedupe/#2-select-delete-record","title":"2. Select Delete record","text":""},{"location":"manual/extraction_dedupe/#3-click-on-delete-record-in-the-confirmation-dialog","title":"3. Click on Delete record in the confirmation dialog","text":""},{"location":"manual/extraction_dedupe/#asana-steps","title":"Asana Steps","text":""},{"location":"manual/extraction_dedupe/#delete-the-duplicate-dataset-task","title":"Delete the duplicate dataset task","text":""},{"location":"manual/extraction_dedupe/#1-right-click-on-the-duplicate-dataset-task","title":"1. Right click on the duplicate dataset task","text":""},{"location":"manual/extraction_dedupe/#2-click-on-delete-task","title":"2. Click on Delete task","text":""},{"location":"manual/extraction_overview/","title":"Overview and Setup","text":""},{"location":"manual/extraction_overview/#extraction-and-validation-overview","title":"Extraction and Validation Overview","text":""},{"location":"manual/extraction_overview/#overview","title":"Overview","text":"<p>Once we have identified articles with relevant datasets, we then need to extract the information about these datasets. We won't have the capacity to get every dataset, so we need to be able to evaluate which datasets are likely to provide the most value. The extraction process is automated, but we still need to check this data is accurate, and do things that like check if the dataset is a duplicate of an existing dataset.</p> <p>In brief, the process of data extraction and validation is:</p> <ol> <li>Articles are identified as ready for AI extraction during the Full Text Screening stage.</li> <li>The AI extraction process is run on these articles to extract the relevant information.    During this process:<ul> <li>The data is uploaded into the Airtable database.</li> <li>The label in Rayyan is updated to indicate that the article has been extracted.</li> <li>A new task is created in Asana to track the dataset.</li> </ul> </li> <li>A human reviewer checks the extracted data for accuracy, and checks if it is a duplicate of an existing dataset.</li> <li>Once satisfied, the human reviewer marks the dataset as 'Validated' in Asana.    This lets us know that the dataset is ready to be evaluated for the value it would add.</li> </ol> <p>As the human reviewer, you come in from the third step onwards. The below docs explain how to do these steps.</p>"},{"location":"manual/extraction_overview/#setup","title":"Setup","text":"<p>To validate data, you will need access to the following tools:</p> <ul> <li>Airtable</li> <li>Asana</li> </ul>"},{"location":"manual/extraction_overview/#data-structure","title":"Data Structure","text":"<p>Before we describe the process, it is worth discussing the way that the data are structured in Airtable.</p> <ul> <li>Each dataset will have one or more articles associated with it.   That is, a dataset might have been used for more than one study, and so it has been reported in more than one article.</li> <li>Each article can have one or more populations.   Most studies will have one population, but some studies will report on different groups, like older or younger children, or boys and girls separately.</li> <li>Each article can have one or more screen time measures.   For example, they might use a time use diary, and also a survey.</li> <li>Each article can have one or more outcomes.   For example, they might report on behaviour problems, and also academic performance.   Sometimes, they will also have multiple measures of the same outcome, like using multiple scales to measure wellbeing.</li> <li>Each outcome has one validated outcome.   As the AI extraction is messy, we need a more consistent way to refer to the outcomes.   For example, the AI might extract \"anxiety symptoms\" and \"anxiety\" as two separate outcomes.   The validated outcome is the consistent way to refer to this, so we can say that both of these outcomes are measuring \"Anxiety\".   This is important for the next step, where we will evaluate the value of each dataset.</li> </ul> <pre><code>flowchart TD\n    Dataset[\"Dataset\"]\n    Article[\"Articles\"]\n    Population[\"Populations\"]\n    ScreenTime[\"Screen Time Measures\"]\n    Outcome[\"Outcomes\"]\n    ValidatedOutcome[\"Validated Outcomes\"]\n\n    Dataset --&gt;|can have many| Article\n    Article --&gt;|can have many| Population\n    Article --&gt;|can have many| ScreenTime\n    Article --&gt;|can have many| Outcome\n    Outcome --&gt;|can have one| ValidatedOutcome</code></pre>"},{"location":"manual/extraction_overview/#airtable-tables","title":"Airtable Tables","text":"<p>Each of the above entities (datasets, articles, etc) has a table in Airtable. Airtable then links these together, so we can see which articles are associated with which datasets, and so on.</p> <p>Below is what is stored in each table, as reference.</p> DatasetsArticlesPopulationsScreen Time MeasuresOutcomesOutcome Options Column Description Example Editable<sup>1</sup> Dataset ID The ID of the dataset. Set by Asana automatically BPIPD-1 Dataset Name The 'name' of the dataset, or the author name and year of the article the dataset was found in. Longitudinal Study of Australian Children Dataset Value The value [0,1] of the dataset. Set automatically. 0.03 Total Sample Size The total number of participants in the dataset 1,000 Dataset Contact Name The name of the person to contact for access to the data John Doe Dataset Contact Email The email of the person to contact for access to the data john.doe@university.com Countries of Data A list of the countries the data were collected in. Australia, New Zealand Articles: IDs The IDs of the articles linked to this dataset (from Rayyan) 215786174 Articles: Titles The titles of the articles linked to this dataset Screens and teens Articles: Corresponding Authors The corresponding authors of the articles linked to this dataset John Doe Articles: Corresponding Author Emails The corresponding authors' emails of the articles linked to this john.doe@university.com Possible Duplicates Links to other datasets which are potentially duplicates that need to be merged BPIPD-2 Column Description Example Editable<sup>1</sup> Rayyan ID The ID of the article in Rayyan 215786174 Article Title Title of the article Screens and teens Authors The names of the authors Doe, J. Journal The journal the article is published in Science DOI The DOI of the article 10.1016/j.chb.2010.10.019 Year Year the article was published 2025 Fulltext An attachment with the full-text of the article Corresponding Author The corresponding author of the article John Doe Corresponding Author Email The corresponding authors' emails john.doe@university.com Year of Last Data Point Year that the data were collected (or last year for longitudinal studies) 2023 Study Design One of [<code>Cross-section</code>, <code>Longitudinal</code>, <code>Experimental</code>, or <code>Other</code>] Cross-sectional Countries of Data A list of the countries the data were collected in. Australia, New Zealand Total Sample Size The total number of participants in the study 1,000 Screen Time Measure Name A list of measures or instruments \"ScreenQ\", \"Custom Survey\" Outcome Groups The broad groups of outcomes in the study \"Mental Health\", \"Wellbeing\" Outcomes The specific outcomes that were measured Anxiety, Depression Column Description Example Editable<sup>1</sup> Population ID The ID for the population 17 Rayyan ID The ID number to link to an article (same as the article's Rayyan ID) 215786174 Article Title Title of the article Screens and teens Age: Lower Range The lower bound of the population age range 8 Age: Upper Range The upper bound of the population age range 12 Age: Mean The mean age of the population 10.8 Sample Size: Total N The total number of participants in the study 1,000 Sample Size: N Girls The total number of girls in the study 645 Sample Size: % Girls The percentage of girls in the study 64.5% Column Description Example Editable<sup>1</sup> Screen Time Measure ID The ID for the screen time measure 17 Rayyan ID The ID number to link to an article (same as the article's Rayyan ID) 215786174 Article Title Title of the article Screens and teens Screen Time Measure: Type The type of instrument used. One of [<code>Diary</code>, <code>Survey</code>, or <code>Other</code>]. Use only one, and add new rows for additional measures. Diary Screen Time Measure: Name The name of the instrument, if known. Otherwise, use 'Custom Survey' or similar. Use only one, and add new rows for additional measures. Media assessment Questionnaire Types of Screen Time Measured The specific type of screen time measured, such as television or social media use. Add multiple for all that were measured with this instrument. Television Locations of Screen Time Measured If the study distinguishes between locations of screen time, they can be listed here. Add multiple for all that were measured with this instrument. Home, General Column Description Example Editable<sup>1</sup> Outcome ID The ID for the outcome 17 Rayyan ID The ID number to link to an article (same as the article's Rayyan ID) 215786174 Outcome Groups The broad group of the outcome. Add only one, and add additional rows for multiple outcomes. Wellbeing Outcome The AI extracted specific outcomes. You do not need to edit this - use the <code>Validated Outcome</code> column instead. Self-esteem Outcome Measure The name of the measure used for the outcome Rosenberg Self-Esteem Scale Validated Outcome The validated outcome. See Adding New Outcomes for instructions. Screens and teens Column Description Example Editable<sup>1</sup> Outcome The name of the outcome Anxiety Outcome Groups The broad group of the outcome. Should only be one of [<code>Behaviour</code>, <code>Cognition</code>, <code>Learning</code>, <code>Mental Health</code>, <code>Wellbeing</code>, or <code>Other</code>] Mental Health <ol> <li> <p>Some fields are not intended to be edited directly.   Hover over the  icon to see why.\u00a0\u21a9\u21a9\u21a9\u21a9\u21a9\u21a9</p> </li> </ol>"},{"location":"manual/extraction_process/","title":"Validating Extracted Data","text":"Note <p>This is a somewhat convoluted process at the moment. We are working on improving it, and feedback is valuable. If you find a way something can be done better, don't keep it to yourself!</p>"},{"location":"manual/extraction_process/#overview-of-steps","title":"Overview of Steps","text":"<p>The processing of validating extracted data is a multi-step process. As a quick overview, the steps are:</p> <ol> <li>Pick a dataset to validate.</li> <li>Check the details of the article attached to the dataset.    In particular, you need to check:<ol> <li>The population details</li> <li>The screen time measure details</li> <li>The outcomes details (including adding a 'validated' outcome to each outcome)</li> </ol> </li> <li>Check the overall dataset details, including confirming that the dataset is not a duplicate.</li> <li>Mark the dataset as 'validated' in Asana.</li> </ol>"},{"location":"manual/extraction_process/#checking-the-extracted-data","title":"Checking the Extracted Data","text":""},{"location":"manual/extraction_process/#choosing-a-dataset-to-validate","title":"Choosing a Dataset to Validate","text":"<p>Start by picking a dataset from the 'Awaiting Triage' set in Asana. Even though this is also shown in Airtable, we use Asana as the 'source of truth' for the stage that a dataset is at. Any dataset that is in the 'Awaiting Triage' set in Asana is ready to be validated.</p> <p></p> <p>In the 'Airtable Data' column, there is a link to the Airtable record for the dataset (highlighted in red above). Clicking the link is the easiest way to open the Airtable record for the dataset.</p>"},{"location":"manual/extraction_process/#checking-the-data","title":"Checking the Data","text":"<p>There are two main ways to check the data: using the 'form' view, or using the filters. Either is fine, but for generally checking the data I find the 'form' view easier to use.</p>"},{"location":"manual/extraction_process/#open-the-forms","title":"Open the forms","text":""},{"location":"manual/extraction_process/#1-open-the-dataset-form","title":"1. Open the dataset form","text":"<p>If you haven't followed the link from Asana, you can open the form view by clicking the two-arrow icon that appears when you hover over a record.</p> <p></p>"},{"location":"manual/extraction_process/#2-open-the-article-form","title":"2. Open the article form","text":"<p>Airtable will 'stack' forms on top of each other, which makes it quite convenient to work down through the layers of data. Before you can validate the dataset fields, you need to check the article. Clicking on the linked article (under 'Articles: IDs') will open the form for the article.</p> <p></p>"},{"location":"manual/extraction_process/#3-download-the-full-text","title":"3. Download the full text","text":"<p>You'll likely want to download the full text (or open it in a new tab) so that you can view it while validating the data.</p> <p></p>"},{"location":"manual/extraction_process/#check-the-article-form","title":"Check the article form","text":"<p>The next steps are to work through each of the populations, screen time measures, and outcomes in the article.</p>"},{"location":"manual/extraction_process/#1-check-the-fields-on-the-article-form","title":"1. Check the fields on the article form","text":"<p>Check the fields on the article form, such as the author details, the year of data collection, the study design, countries of data, and the total sample size.</p>"},{"location":"manual/extraction_process/#2-open-the-hidden-fields","title":"2. Open the hidden fields","text":""},{"location":"manual/extraction_process/#check-the-population-forms","title":"Check the population form(s)","text":"<p>If there are multiple populations, repeat for each one.</p>"},{"location":"manual/extraction_process/#1-open-the-population-forms","title":"1. Open the population form(s)","text":""},{"location":"manual/extraction_process/#2-check-the-population-fields","title":"2. Check the population fields","text":"<p>In particular, check the sample size and proportion of girls. Remember that you can add or remove populations as needed. Each one needs it's own record.</p>"},{"location":"manual/extraction_process/#3-when-you-are-done-close-the-population-form","title":"3. When you are done, close the population form","text":""},{"location":"manual/extraction_process/#check-the-screen-time-measures","title":"Check the screen time measure(s)","text":"<p>If there are multiple screen time measures, repeat for each one.</p>"},{"location":"manual/extraction_process/#1-open-the-screen-time-measures","title":"1. Open the screen time measure(s)","text":""},{"location":"manual/extraction_process/#2-check-the-screen-time-measure-fields","title":"2. Check the screen time measure fields","text":"<p>Remember that you can add or remove screen time measures if the AI has made a mistake.</p>"},{"location":"manual/extraction_process/#3-when-finished-click-the-close-button","title":"3. When finished, click the close button","text":""},{"location":"manual/extraction_process/#check-the-outcome-forms","title":"Check the outcome form(s)","text":"<p>If there are multiple outcomes, repeat for each one. Remember that you can add or remove outcomes if the AI has made a mistake.</p>"},{"location":"manual/extraction_process/#1-open-the-outcomes","title":"1. Open the outcome(s)","text":""},{"location":"manual/extraction_process/#2-check-the-outcome-fields-and-add-the-validated-outcome","title":"2. Check the outcome fields and add the validated outcome","text":"<p>Start by checking the already extracted outcome fields are correct.</p> Tip <p>You do not need to edit the Outcome field. Use this to guide you in selecting the correct validated outcome, but because of the way the AI extraction works, it is too time-consuming to fix this field. You should update the Outcome Group and the Outcome Measure fields, however.</p>"},{"location":"manual/extraction_process/#3-for-each-outcome-add-a-validated-outcome","title":"3. For each outcome add a 'validated' outcome","text":"<p>You can read the full instructions for adding a validated outcome in the next section. Briefly, the steps are:</p> <ol> <li>Click the 'Add option' button.    </li> <li>Search for an existing matching outcome.    If you fine one, select it and you are done.</li> <li>If there isn't an existing one, add a new one and complete the required fields.</li> </ol>"},{"location":"manual/extraction_process/#4-when-finished-click-the-close-button","title":"4. When finished, click the close button","text":""},{"location":"manual/extraction_process/#check-the-dataset-form","title":"Check the dataset form","text":"<p>Once all of the data for the article has been checked, you can check the dataset fields. In particular, if you changed the sample size or the corresponding author, you should also update these fields in the dataset form.</p> <p></p>"},{"location":"manual/extraction_process/#updating-the-record-in-asana","title":"Updating the record in Asana","text":""},{"location":"manual/extraction_process/#checklist","title":"Checklist","text":"<p>When you are satisfied that the data in Airtable is correct, you can update the record in Asana to indicate that the dataset has been validated. Before doing this, check that you have:</p> <ul> <li> Checked the dataset and article details are correct</li> <li> Removed any incorrect populations, screen time measures, or outcomes</li> <li> Added any additional populations, screen time measures, or outcomes that were not extracted by the AI</li> <li> Checked that the dataset is not a duplicate</li> </ul>"},{"location":"manual/extraction_process/#update-the-asana-task","title":"Update the Asana task","text":"Tip <p>Make sure you use the 'Dataset ID' (e.g., <code>BPIPD-01</code>) to find the dataset in Asana. Don't rely on the name - it may not be unique!</p> <p>That's it! You have successfully validated a dataset.</p>"},{"location":"manual/extraction_process/#1-find-the-dataset-in-asana","title":"1. Find the dataset in Asana","text":""},{"location":"manual/extraction_process/#2-click-on-awaiting-triage","title":"2. Click on Awaiting Triage","text":""},{"location":"manual/extraction_process/#3-click-on-validated","title":"3. Click on Validated","text":""},{"location":"manual/screening_overview/","title":"Screening Overview","text":""},{"location":"manual/screening_overview/#overview","title":"Overview","text":"<p>The purpose of screening is to identify articles that contain datasets relevant to the Bigger Picture project. This process involves two main steps:</p> <ol> <li>Title and Abstract Screening: Initial screening of articles based on their titles and abstracts to remove completely irrelevant articles.</li> <li>Full Text Screening: A more detailed review of the full text of articles that passed the initial screening to determine if they contain relevant datasets.</li> </ol> <p>The below outlines the process for screening articles, and the criteria we use to determine whether an article is relevant to the Bigger Picture project.</p>"},{"location":"manual/screening_overview/#setup","title":"Setup","text":"<p>To begin screening, you will need access to the Bigger Picture Project on Rayyan. If you don't have access, please let Taren know.</p>"},{"location":"manual/screening_overview/#inclusion-and-exclusion-criteria","title":"Inclusion and Exclusion Criteria","text":"<p>The below are the criteria that we use to assess whether an article is relevant to the Bigger Picture project. You should read these carefully before beginning the screening process. Note that you can also access these criteria in Rayyan by clicking the  icon in the top right corner of the screen.</p> Tip <p>You can also press the C key to open the criteria in Rayyan.</p> Inclusion CriteriaExclusion Criteria Study Design <p>Cross-sectional, longitudinal studies, or control groups from experimental studies</p> Population <p>Have a mean sample age younger than 18 years. If a mean study age is not available, we will use the midpoint of the age range.</p> Independent Variable <p>Quantitative disaggregated measure of screen time exposure (e.g., time spent on social media, time spent on smartphones, time spent watching tv, time spent on schoolwork or educational content, watching vs interactive use).</p> Outcomes <p>Quantitative measurement of at least one outcome related to children's learning, cognitive abilities, mental health, wellbeing, or behaviour. Examples include:</p> <ul> <li>Learning: General education, numeracy, literacy</li> <li>Cognitive abilities: Executive function, cognitive function</li> <li>Mental health: Anxiety, Depression, Emotions</li> <li>Behaviour: Aggression, Self-regulation, Prosocial behaviour</li> </ul> <p>Note</p> <p>The label used in Rayyan is the part in bold below. You only need to supply a label for a reason you are excluding an article when you are screening at the full text stage. You do not need to supply a label for the title and abstract stage.</p> Wrong screen time measurement <p>Meets any of the following criteria:</p> <ul> <li>Only measured total or aggregated screen time and does not specify the type of screen activity (e.g., TV, social media, video games) and/or content (e.g., educational vs. recreational).   Note, studies will be included if disaggregated screen time data was collected, even if only aggregated results were reported.</li> <li>Does not specify the type of screen activity (e.g., TV, social media, video games) and/or content (e.g., educational vs. recreational).</li> <li>Only measured \u2018problematic screen use\u2019 (e.g., internet addiction scales) which do not provide time-based measurements</li> <li>Only has a dichotomous measure of screen use (e.g., \u2018meets guidelines\u2019 or \u2018does not meet guidelines\u2019).   Note, studies will be included if they measure screen time in time units, then converted to a dichotomous measure.</li> <li>Screen time measured is not ecologically valid.   That is, screen time should be measured in a way that reflects real-world use.   Studies where they have experimentally manipulated screen time (e.g., having children watch a show in the lab) are excluded.   An example of experimental screen time study that would be included are if they placed a restriction on children\u2019s screen time and screen time was still ecological.</li> </ul> Wrong outcome <p>Does not include at least one quantitatively measured outcome related to learning, cognitive abilities, mental health, wellbeing, or behaviour.</p> Wrong age <p>Mean sample age older than 18 years. If the mean age is unclear and the age range midpoint is \u226518 years</p> Foreign Language <p>Full-text not available in English</p> Wrong study design <p>Study designs that cannot contribute to IPD including:</p> <ul> <li>Systematic reviews, meta-analyses, or narrative reviews</li> <li>Qualitative-only designs</li> <li>Studies that only report group-level associations (e.g., screen use rates and test scores by country)</li> <li>Case studies or case reports with no participant-level quantitative data</li> </ul> Data availability statement states that data cannot be shared. <p>Data availability statement states that data cannot be shared. This may be stated in the data availability section in full-text.</p> PDF not available <p>Cannot retrieve full-text</p>"},{"location":"manual/screening_process/","title":"Screening Process","text":"<p>We are only screening articles once, rather than screening in duplicate as is common in systematic reviews. We may later go back and double-screen articles that were excluded to ensure we haven't missed anything, but our priority is to get through the screening process as quickly as possible so that we can start contacting authors. When screening in Rayyan, it is important to set the filters so that you are only seeing articles that have not been screened yet, as this is not the default.</p>"},{"location":"manual/screening_process/#title-and-abstract-screening","title":"Title and Abstract Screening","text":"<p>The goal of the title and abstract stage is just to remove articles that are clearly irrelevant to the Bigger Picture project. We aim to do this bit as quickly as possible - don't labour over decisions at this stage. If you are on the fence about an article, it is best to include it and review it in the full text stage.</p>"},{"location":"manual/screening_process/#setup-rayyan-for-title-and-abstract-screening","title":"Setup Rayyan for Title and Abstract Screening","text":"<ol> <li>Log in to Rayyan and navigate to the Bigger Picture Project.</li> <li>Click on the Screening tab.</li> <li> <p>Set the filters to show only articles that need to be screened:</p> <ul> <li> <p>The filter by inclusion at the top of the list of articles should be set to 'Undecided':</p> <p></p> </li> <li> <p>The 'Max member Decisions' filter should be set to 'At most 0' (that is, articles that have not been screened by anyone yet):</p> <p></p> </li> </ul> </li> </ol> <p>You are welcome to use the other filters to speed up the process. Some useful filters are:</p> <ul> <li>Keywords for Include/Exclude: These are words that we have identified as common in either articles that are usually included or excluded.</li> </ul>"},{"location":"manual/screening_process/#screening-title-and-abstracts","title":"Screening Title and Abstracts","text":"<p>Use the  or  buttons to screen articles. Avoid using the  button, as this just requires it to be screened again later.</p> <p>The fastest way to screen articles is to use the keyboard shortcuts in Rayyan. Use the I key to include an article, the E key to exclude it.</p> Tip <p>You can quickly view the keyboard shortcuts in Rayyan by pressing the V key.</p>"},{"location":"manual/screening_process/#full-text-screening","title":"Full Text Screening","text":""},{"location":"manual/screening_process/#setup-rayyan-for-full-text-screening","title":"Setup Rayyan for Full Text Screening","text":"<p>Setting up Rayyan is the same as for Title and Abstract Screening. Navigate to the Full Text Screening tab and apply the same filters as above. You may also want to filter by if an article already has a PDF attached by setting the 'Full Text' filter to 'Private' ().</p>"},{"location":"manual/screening_process/#screening-full-texts","title":"Screening Full Texts","text":"<p>There are two main differences between the full text screening and the title and abstract screening:</p> <ol> <li> <p>When you exclude an article, you need to provide a reason.    You do this using the 'Exclude with Reasons' box at the bottom of the screen.</p> Tip <p>You can quickly access the exclusion reasons by pressing the R key.</p> </li> <li> <p>When you include an article, you need to add a label that tells our software that it is ready to be extracted. (1)    When you have included an article, please add the label <code>Included: Not Yet Extracted</code> to the article.    Note that this label is case-sensitive, so you need to type it exactly as shown (or better yet, copy and paste it).    You can add a label by clicking in the labels box at the bottom of the screen.    If you have already added the label to another article, it should appear in the list of options.</p> Warning <p>A common issue is that clicking 'Include' automatically moves you to the next article. That means that if you then add the label, it will not be applied to the article you just included. To avoid this, add the label first, then click 'Include'. Adding the label doesn't change the article that you are currently viewing.</p> </li> </ol> <ol> <li>For some inexplicable reason, the Rayyan API does not differentiate between articles included at the title and abstract stage and those included at the full text stage.    So, we have to use a label to indicate that an article is ready for extraction.</li> </ol>"},{"location":"manual/screening_process/#other-useful-information","title":"Other Useful Information","text":""},{"location":"manual/screening_process/#rayyan-ratings","title":"Rayyan Ratings","text":"<p>Rayyan provides a function that rates how likely an article is the be relevant to the review. This can be useful for deciding which articles to screen first (those likely to be relevant, or most likely to be irrelevant). The method for using rating is described in the Rayyan documentation. It only works at the title and abstract stage.</p>"},{"location":"manual/screening_process/#potentially-relevant-systematic-reviews","title":"Potentially Relevant Systematic Reviews","text":"<p>If you find a systematic review that is potentially relevant (i.e., it looks like it might have studies in it that could be included), please add the <code>Potentially Relevant Systematic Review</code> label to the article. Eventually, we will go through these and check if we have missed any articles that should be included.</p>"}]}